{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcuSivmZ/mmAWfRakwabeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnudeepReddy-Katta/RNNs-LSTM-Attention/blob/main/Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6LD0S8v0lWj"
      },
      "source": [
        "import pandas as pd\n",
        "datasetSentences = pd.read_csv((\"/content/drive/MyDrive/NLP/datasetSentences.txt\"), sep=\"\\t\", skiprows=[0], names=['sentence_index','sentence'])\n",
        "sentiment_labels = pd.read_csv((\"/content/drive/MyDrive/NLP/sentiment_labels.txt\"), sep=\"|\", skiprows=[0], names=['phrase_id','sentiment_values'])\n",
        "dictionary = pd.read_csv((\"/content/drive/MyDrive/NLP/dictionary.txt\"), sep=\"|\", names=['phrase','phrase_id'])"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q-P_HlDNe0S"
      },
      "source": [
        "def pre_process_sentences(string):\n",
        "  string=string.replace('-LRB-','(')\n",
        "  string=string.replace('-RRB-',')')\n",
        "  string=string.replace('Â', '')\n",
        "  string=string.replace('Ã©', 'e')\n",
        "  string=string.replace('Ã¨', 'e')\n",
        "  string=string.replace('Ã¯', 'i')\n",
        "  string=string.replace('Ã³', 'o')\n",
        "  string=string.replace('Ã´', 'o')\n",
        "  string=string.replace('Ã¶', 'o')\n",
        "  string=string.replace('Ã±', 'n')\n",
        "  string=string.replace('Ã¡', 'a')\n",
        "  string=string.replace('Ã¢', 'a')\n",
        "  string=string.replace('Ã£', 'a')\n",
        "  string=string.replace('\\xc3\\x83\\xc2\\xa0', 'a')\n",
        "  string=string.replace('Ã¼', 'u')\n",
        "  string=string.replace('Ã»', 'u')\n",
        "  string=string.replace('Ã§', 'c')\n",
        "  string=string.replace('Ã¦', 'ae')\n",
        "  string=string.replace('Ã­', 'i')\n",
        "  string=string.replace('\\xa0', ' ')\n",
        "  string=string.replace('\\xc2', '')\n",
        "  return string"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54KIoKiQ0fyU"
      },
      "source": [
        "datasetSentences['sentence'] = datasetSentences['sentence'].apply(pre_process_sentences)"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV_KhbKz0aCO"
      },
      "source": [
        "def pre_process_phrases(string):\n",
        "    string=string.replace('é','e')\n",
        "    string=string.replace('è','e')\n",
        "    string=string.replace('ï','i')\n",
        "    string=string.replace('í','i')\n",
        "    string=string.replace('ó','o')\n",
        "    string=string.replace('ô','o')\n",
        "    string=string.replace('ö','o')\n",
        "    string=string.replace('á','a')\n",
        "    string=string.replace('â','a')\n",
        "    string=string.replace('ã','a')\n",
        "    string=string.replace('à','a')\n",
        "    string=string.replace('ü','u')\n",
        "    string=string.replace('û','u')\n",
        "    string=string.replace('ñ','n')\n",
        "    string=string.replace('ç','c')\n",
        "    string=string.replace('æ','ae')\n",
        "    string=string.replace('\\xa0', ' ')\n",
        "    string=string.replace('\\xc2', '')    \n",
        "    return string"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsZQDznTN47W"
      },
      "source": [
        "dictionary['phrase'] = dictionary['phrase'].apply(pre_process_phrases)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "EKXx4isP066T",
        "outputId": "106940af-3fe6-487a-b74c-56fb788c746e"
      },
      "source": [
        "df1 = pd.merge(sentiment_labels,dictionary,on='phrase_id')\n",
        "df1.drop(columns=['phrase_id'],inplace = True)\n",
        "df1.head()"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.44444</td>\n",
              "      <td>' (</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>' ( the cockettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.42708</td>\n",
              "      <td>' ( the cockettes )</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment_values               phrase\n",
              "0           0.50000                    !\n",
              "1           0.50000                    '\n",
              "2           0.44444                  ' (\n",
              "3           0.50000    ' ( the cockettes\n",
              "4           0.42708  ' ( the cockettes )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "6WlSZIJ906-W",
        "outputId": "a68fc55e-d4f1-4717-e978-434e03d40496"
      },
      "source": [
        "df2 = pd.merge(df1,datasetSentences,left_on='phrase',right_on='sentence')\n",
        "df2.drop(columns = ['phrase','sentence_index'],inplace = True)\n",
        "df2.head()"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013889</td>\n",
              "      <td>... a bland murder-on-campus yawner .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.263890</td>\n",
              "      <td>... a hollow joke told by a cinematic gymnast ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.472220</td>\n",
              "      <td>... the picture 's cleverness is ironically mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.875000</td>\n",
              "      <td>classic cinema served up with heart and humor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.319440</td>\n",
              "      <td>entertaining enough , but nothing new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment_values                                           sentence\n",
              "0          0.013889              ... a bland murder-on-campus yawner .\n",
              "1          0.263890  ... a hollow joke told by a cinematic gymnast ...\n",
              "2          0.472220  ... the picture 's cleverness is ironically mu...\n",
              "3          0.875000      classic cinema served up with heart and humor\n",
              "4          0.319440              entertaining enough , but nothing new"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VtbURWj07CA"
      },
      "source": [
        "df2.loc[(df2['sentiment_values']>=0) & (df2['sentiment_values']<=0.2),'label']=0\n",
        "df2.loc[(df2['sentiment_values']>0.2) & (df2['sentiment_values']<=0.4),'label']=1\n",
        "df2.loc[(df2['sentiment_values']>0.4) & (df2['sentiment_values']<=0.6),'label']=2\n",
        "df2.loc[(df2['sentiment_values']>0.6) & (df2['sentiment_values']<=0.8),'label']=3\n",
        "df2.loc[(df2['sentiment_values']>0.8) & (df2['sentiment_values']<=1),'label']=4\n",
        "df2.drop(columns = ['sentiment_values'],inplace = True)\n",
        "df2.rename(columns={'label':'sentiment_values'},inplace = True)\n",
        "df2['sentiment_values'] = df2['sentiment_values'].astype('int')"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oevsb6BcPDW4",
        "outputId": "5076c428-3b63-4df9-8c5c-47df86fa8f40"
      },
      "source": [
        "df2['sentiment_values'].value_counts()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3140\n",
              "3    3111\n",
              "2    2242\n",
              "4    1851\n",
              "0    1510\n",
              "Name: sentiment_values, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u6jwug31Jr2",
        "outputId": "04bb4544-da9e-47b1-bbd0-b03523998d52"
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThX1bmMe1Ozg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df2, test_size=0.3, random_state=42, stratify=df2['sentiment_values'])"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI-74FJG19jK"
      },
      "source": [
        "train = train.reset_index()\n",
        "train.drop(columns='index',inplace=True)\n",
        "test =test.reset_index(drop=True)"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZX5y5yj1inf",
        "outputId": "86d7a269-6d64-44c3-d8ae-b13f787ac4ee"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1255576310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkF8JgFC1laI"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U1S94xm1ocr"
      },
      "source": [
        "fields = [('sentences', Sentence),('labels',Label)]"
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLhOX2t91rfF"
      },
      "source": [
        "example = [data.Example.fromlist([train.sentence[i],train.sentiment_values[i]], fields) for i in range(train.shape[0])]"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DePYOsmS2Hr1"
      },
      "source": [
        "train_data = data.Dataset(example, fields)"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_l3yE2v2Jp3"
      },
      "source": [
        "example_test = [data.Example.fromlist([test.sentence[i],test.sentiment_values[i]], fields) for i in range(test.shape[0])]"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorz2sNJ2JsX"
      },
      "source": [
        "valid_data = data.Dataset(example_test, fields)"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-QVtmC22Juy",
        "outputId": "ac4c2d38-e2ee-4c2b-fc00-b0013d2f6a25"
      },
      "source": [
        "(len(train_data), len(valid_data))"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8297, 3557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SQycATq2Jw6",
        "outputId": "68593b7c-199a-41b9-ff9b-8e0556a102da"
      },
      "source": [
        "vars(valid_data.examples[50])"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 2,\n",
              " 'sentences': ['It',\n",
              "  'will',\n",
              "  'break',\n",
              "  'your',\n",
              "  'heart',\n",
              "  'many',\n",
              "  'times',\n",
              "  'over',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JQOGgld2J1Q"
      },
      "source": [
        "Sentence.build_vocab(train_data)\n",
        "Label.build_vocab(train_data)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q68V4Kga2U2W",
        "outputId": "b6f67b8d-7dd6-4b2c-b183-33225260ef1e"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  16965\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('.', 7814), (',', 6948), ('the', 5839), ('and', 4266), ('a', 4237), ('of', 4235), ('to', 3023), ('-', 2654), (\"'s\", 2496), ('is', 2422)]\n",
            "Labels :  defaultdict(None, {1: 0, 3: 1, 2: 2, 4: 3, 0: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWVXPIyu2ffE"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppj7kRWB2fiH"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, valid_data), batch_size = 64, \n",
        "                                                            sort_key = lambda x: len(x.sentences),\n",
        "                                                            sort_within_batch=True, \n",
        "                                                            device = device)"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo34nt_bgsm9"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI0PG8P8g8IU"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True,\n",
        "                           bidirectional=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyBkZSjBgvQA"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYYZIrWKhFCo",
        "outputId": "c2c6ecfb-baba-4b5d-8c4a-1aeb8563d22b"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(16965, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "The model has 5,653,205 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRMBiQS5hJEI"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcqh4tGhYQX"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        sent, sent_lengths = batch.sentences   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sent, sent_lengths).squeeze()  \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = categorical_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIVhcH4ohbvT"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sent, sent_lengths = batch.sentences\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sent, sent_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = categorical_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6rG-uUUhghs",
        "outputId": "c021fffb-86ac-4b27-faea-4af9d469b38a"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.575 | Train Acc: 28.42%\n",
            "\t Val. Loss: 1.560 |  Val. Acc: 31.57% \n",
            "\n",
            "\tTrain Loss: 1.526 | Train Acc: 36.89%\n",
            "\t Val. Loss: 1.534 |  Val. Acc: 35.08% \n",
            "\n",
            "\tTrain Loss: 1.441 | Train Acc: 45.76%\n",
            "\t Val. Loss: 1.524 |  Val. Acc: 36.26% \n",
            "\n",
            "\tTrain Loss: 1.347 | Train Acc: 56.49%\n",
            "\t Val. Loss: 1.520 |  Val. Acc: 36.46% \n",
            "\n",
            "\tTrain Loss: 1.259 | Train Acc: 65.64%\n",
            "\t Val. Loss: 1.528 |  Val. Acc: 35.84% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg7clE2thpxW"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    \n",
        "    categories = {0: \"very negative\", 1:\"negative\", 2:\"neutral\", 3:\"positive\", 4:\"very positive\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    pred = prediction.argmax(1)\n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM6LG8GD7Moi",
        "outputId": "20fe0034-d75a-4d1d-f72d-3b8fba7b13f4"
      },
      "source": [
        "for i in range(10):\n",
        "  print(test.sentence[i])\n",
        "  print(\"predicted: \", classify_sentence(test.sentence[i]))\n",
        "  print(\"actual: \", test.sentiment_values[i])\n",
        "  print('\\n')"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The performances are so leaden , Michael Rymer 's direction is so bloodless and the dialogue is so corny that the audience laughs out loud .\n",
            "predicted:  very negative\n",
            "actual:  1\n",
            "\n",
            "\n",
            "Lacks the inspiration of the original and has a bloated plot that stretches the running time about 10 minutes past a child 's interest and an adult 's patience .\n",
            "predicted:  very negative\n",
            "actual:  0\n",
            "\n",
            "\n",
            "Works because , for the most part , it avoids the stupid cliches and formulaic potholes that befall its brethren .\n",
            "predicted:  very negative\n",
            "actual:  3\n",
            "\n",
            "\n",
            "Cox is far more concerned with aggrandizing madness , not the man , and the results might drive you crazy .\n",
            "predicted:  neutral\n",
            "actual:  2\n",
            "\n",
            "\n",
            "Stanley Kwan has directed not only one of the best gay love stories ever made , but one of the best love stories of any stripe .\n",
            "predicted:  negative\n",
            "actual:  4\n",
            "\n",
            "\n",
            "Grown-up quibbles are beside the point here .\n",
            "predicted:  very negative\n",
            "actual:  2\n",
            "\n",
            "\n",
            "Though the book runs only about 300 pages , it is so densely packed ... that even an ambitious adaptation and elaborate production like Mr. Schepisi 's seems skimpy and unclear .\n",
            "predicted:  very negative\n",
            "actual:  1\n",
            "\n",
            "\n",
            "In the process , they demonstrate that there 's still a lot of life in Hong Kong cinema .\n",
            "predicted:  very negative\n",
            "actual:  3\n",
            "\n",
            "\n",
            "Highly recommended viewing for its courage , ideas , technical proficiency and great acting .\n",
            "predicted:  negative\n",
            "actual:  4\n",
            "\n",
            "\n",
            "This is rote drivel aimed at Mom and Dad 's wallet .\n",
            "predicted:  very negative\n",
            "actual:  1\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrkycdv77M-o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}